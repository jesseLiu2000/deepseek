nohup: ignoring input
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:01<00:06,  1.14s/it]Loading checkpoint shards:  29%|██▊       | 2/7 [00:02<00:05,  1.17s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:04,  1.21s/it]Loading checkpoint shards:  43%|████▎     | 3/7 [00:03<00:05,  1.32s/it]
Traceback (most recent call last):
  File "eval_raw_model.py", line 31, in <module>
    model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map="auto", trust_remote_code=True)
  File "/home/zx22/.local/lib/python3.8/site-packages/transformers/models/auto/auto_factory.py", line 558, in from_pretrained
    return model_class.from_pretrained(
  File "/home/zx22/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3531, in from_pretrained
    ) = cls._load_pretrained_model(
  File "/home/zx22/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 3958, in _load_pretrained_model
    new_error_msgs, offload_index, state_dict_index = _load_state_dict_into_meta_model(
  File "/home/zx22/.local/lib/python3.8/site-packages/transformers/modeling_utils.py", line 812, in _load_state_dict_into_meta_model
    set_module_tensor_to_device(model, param_name, param_device, **set_module_kwargs)
  File "/home/zx22/.local/lib/python3.8/site-packages/accelerate/utils/modeling.py", line 387, in set_module_tensor_to_device
    new_value = value.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 39.39 GiB of which 10.50 MiB is free. Process 1257574 has 716.00 MiB memory in use. Process 1383684 has 1.03 GiB memory in use. Process 1398762 has 802.00 MiB memory in use. Process 1908066 has 17.56 GiB memory in use. Including non-PyTorch memory, this process has 19.28 GiB memory in use. Of the allocated memory 15.72 GiB is allocated by PyTorch, and 3.15 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
